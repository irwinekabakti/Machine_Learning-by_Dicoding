# -*- coding: utf-8 -*-
"""Copy of TS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qB6Og11G1HyiMja_Q1V32vedNZs_2Rek
"""

!chmod 600 /content/kaggle.json

! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d emmanuelfwerr/london-weather-data

import zipfile
zip_file = zipfile.ZipFile('/content/london-weather-data.zip')
zip_file.extractall('/tmp/')

import pandas as pd

df_train = pd.read_csv('/tmp/london_weather.csv')
df_train.head(10)

df_train.shape

df_train.info

import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from keras.layers import Dense, LSTM

df_train.isnull().sum()

df_train['date'] = pd.to_datetime(df_train['date'])
df_train['date'].head()
df_train['mean_temp'].fillna(df_train['mean_temp'].mean(), inplace = True)
df_train = df_train[['date', 'mean_temp']]

df_train.head()

df_train.info()

london = df_train[['date', 'mean_temp']].copy()
london['only_date'] = london['date'].dt.date

london_final = london.drop('date', axis = 1)
london_final.set_index('only_date', inplace = True)
london_final.head()

london_final.info()

plt.figure(figsize = (18, 8))
plt.plot(london_final)
plt.title('London Weather')
plt.xlabel('Date')
plt.ylabel('Mean Temperature')
plt.show()

date_values = df_train['date'].values
temperature_values = df_train['mean_temp'].values

def windowed_dataset(series, window_size, batch_size,shuffle_buffer):
  series = tf.expand_dims(series, axis = 1)
  data_set = tf.data.Dataset.from_tensor_slices(series)
  data_set = data_set.window(window_size + 1, shift = 1, drop_remainder = True)
  data_set = data_set.flat_map(lambda w: w.batch(window_size + 1))
  data_set = data_set.shuffle(shuffle_buffer)
  data_set = data_set.map(lambda w: (w[:-1], w[-1:]))
  return data_set.batch(batch_size).prefetch(1)

x_train, x_test, y_train, y_test = train_test_split(temperature_values, date_values, test_size = 0.2, random_state = 0 , shuffle=False)
print(len(x_train), len(x_test))

data_x_train = windowed_dataset(x_train, window_size=60, batch_size=30, shuffle_buffer=5000)
data_x_test = windowed_dataset(x_test, window_size=60, batch_size=30, shuffle_buffer=5000)

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv1D(filters=32, kernel_size=5,
                      strides=1, padding="causal",
                      activation="relu",
                      input_shape=[None, 1]),
  tf.keras.layers.LSTM(64, return_sequences=True),
  tf.keras.layers.LSTM(64, return_sequences=True),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dense(1),
  tf.keras.layers.Lambda(lambda x: x * 400)
])

lr_schedule = tf.keras.callbacks.LearningRateScheduler(
    lambda epoch: 1e-8 * 10**(epoch / 20))
optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer = optimizer,
              metrics=["mae"])

max = df_train['mean_temp'].max()
min = df_train['mean_temp'].min()
mae_x = (max - min) * 0.1
print(mae_x)

# callback
class historyCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae') < mae_x):
      self.model.stop_training = True
      print("\n value of MAE is less than < 10% of data scale and forced to stop")
callbacks = historyCallback()

tf.keras.backend.set_floatx('float64')
history = model.fit(data_x_train,
                    epochs = 200,
                    validation_data = data_x_test,
                    callbacks=[callbacks])

# Graphic Plot of MAE
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('Graphic MAE Value')
plt.ylabel('mae')
plt.xlabel('epoch')
plt.legend(['Data Train', 'Data Test'], loc='upper left')
plt.show()


# Graphic Plot of LOSS
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Graphic Loss Value')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['Data Train', 'Data Test'], loc='upper left')
plt.show()